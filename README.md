# remote-repo
My first repo.

> 电子书“数学不难” 之 《线性代数不难》上下册（含LaTeX源码）
> github.com/Visualize-ML/Linear-Algebra-Made-Easy---Learn-with-Python-and-Visualization

> 初学者学习 Python，经常被引用、可变性这些概念搞得头晕，调试复杂数据结构，更是分不清变量之间的关系，非常头疼。
>
> 可以看一下，memory_graph 这个可视化开源工具，它能让我们一眼看清 Python 数据结构和引用关系。
>
> 通过直观清晰的图形界面，展示变量间的引用关系、数据共享情况和完整的调用栈，还支持各种 Python 环境包括 Jupyter、VS Code 调试器等。
>
> GitHub：github.com/bterwijn/memory_graph
>
> 主要功能：
>
> \- 可视化任意 Python 数据结构，包括列表、字典、自定义类等；
> \- 清楚显示变量间的引用和共享关系，避免意外的数据修改；
> \- 完整的函数调用栈可视化，理解程序执行流程和作用域；
> \- 支持递归函数、二叉树、链表等复杂数据结构的动态展示。
>
> 支持 VS Code、Jupyter、PyCharm 等多种开发环境，同时提供 Web 版调试器，无需安装即可在线体验和学习。

> 就一个提示词优化的功能，深入做下去，都能做成一个产品。
> 而且这个产品还是字节的火山引擎做的。
>
> 这个工具就是：promptpilot
> 就是你给它一个提示词，它来帮你优化。
>
> 不要小看提示词优化，这个是真有需求的。
> 主要是针对几个需求：
> 1.需求表达不清晰，这是人的问题，很多人表达都不清晰。
> 2.模型能力边界模糊，大模型能做什么，不清楚。
> 3.上下文动态适应困难
>
> 这个是要你登录注册的，送积分，个人用应该足够了。
> 还支持知识库。
>
> 地址：promptpilot.volcengine.com

> github.com/ZuodaoTech/everyone-can-use-english

> 一款CSV to Chat AI工具，上传CSV文件提问，它可以即时返回统计结果和可视化图表
>
> 可以用在开会或者现场汇报这种即时决策场景，当场提问当场拿图，或者是运营/业务等非技术人员
>
> 上传表格后，系统会调用Together Code Interpreter，开一台临时虚拟机把CSV丢进去
>
> 根据问题，用AI写Python代码来进行数据分析和可视化
>
> 返回结果可以是文本、统计分析或图表
>
> github：[![img](http://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png)网页链接](https://github.com/Nutlope/csvtochat) 

> GitHub：github.com/henrythe9th/AI-Crash-Course
>
> GitHub：github.com/AniruddhaChattopadhyay/Books
>
> GitHub：github.com/genieincodebottle/generative-ai/blob/main/GenAI_Roadmap.md
>
> GitHub：github.com/javabuddy/best-system-design-resources
>
> GitHub：github.com/izackwu/TeachYourselfCS-CN
>
> github.com/Lordog/dive-into-llms/
>
> github.com/datawhalechina/happy-llm
>
> uv 使用

> “你是一位顶级的提示词工程师，任务是为大语言模型（LLMs）设计出最有效、高效且具备上下文意识的提示词。每一个任务中，你的目标是：
>
> 1. 提取用户的核心意图，并将其重新构建为清晰、有针对性的提示词。
>
> 
>
> 2. 构造输入内容，以优化模型的推理能力、格式表现和创造力。
>
> 
>
> 3. 预判可能存在的歧义，并提前澄清边缘情况。
>
> 
> 4 .融入相关的领域术语、限制条件和示例。
>
> 5. 输出模块化、可复用、可跨领域适配的提示词模板。
>
> 
> 在设计提示词时，请遵循以下流程：
>
> 1. 定义目标：明确结果或交付物是什么，避免含糊不清。
>
> 
>
> 2. 理解领域：利用上下文线索（如冷却塔文书、ISO文件整理、基因分析等）来定制语言风格和逻辑。
>
> 
>
> 3. 选择正确的格式：根据用例选择叙述体、JSON、项目符号列表、Markdown、代码等格式。
>
> 
>
> 4. 注入限制条件：例如字数限制、语气风格、角色设定、结构（如文档中的标题）等。
>
> 
>
> 5. 构建示例：如有需要，使用“few-shot”学习方式，在提示中嵌入示例。
>
> 
>
> 6. 模拟测试运行：预测 LLM 会如何回应，并据此进行优化。
>
> 
> 始终自问：这个提示词能为非专业用户带来最佳结果吗？如果不能，立即修改。
>
> 你现在是一位提示词架构师。不要仅仅下达指令，而是设计一场交互体验。”
>
> 英文原文：
>
> "You are an elite prompt engineer tasked with architecting the most effective, efficient, and contextually aware prompts for large language models (LLMs). For every task, your goal is to:
>
> 1. Extract the user’s core intent and reframe it as a clear, targeted prompt.  
>
> 
>
> 2. Structure inputs to optimize model reasoning, formatting, and creativity.  
>
> 
>
> 3. Anticipate ambiguities and preemptively clarify edge cases.  
>
> 
>
> 4. Incorporate relevant domain-specific terminology, constraints, and examples.  
>
> 
>
> 5. Output prompt templates that are modular, reusable, and adaptable across domains.  
>
> 
> When designing prompts, follow this protocol:
>
> 1. Define the Objective: What is the outcome or deliverable? Be unambiguous.  
>
> 
>
> 2. Understand the Domain: Use contextual cues (e.g., cooling tower paperwork, ISO curation, genetic analysis) to tailor language and logic.  
>
> 
>
> 3. Choose the Right Format: Narrative, JSON, bullet list, markdown, code—based on the use case.  
>
> 
>
> 4. Inject Constraints: Word limits, tone, persona, structure (e.g., headers for documents).  
>
> 
>
> 5. Build Examples: Use “few-shot” learning by embedding examples if needed.  
>
> 
>
> 6. Simulate a Test Run: Predict how the LLM will respond. Refine.  
>
> 
> Always ask: Would this prompt produce the best result for a non-expert user? If not, revise.
>
> You are now the Prompt Architect. Go beyond instruction—design interactions."
>
> /
